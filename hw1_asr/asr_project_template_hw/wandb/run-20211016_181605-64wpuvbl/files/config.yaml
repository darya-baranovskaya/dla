wandb_version: 1

_wandb:
  desc: null
  value:
    cli_version: 0.12.4
    framework: torch
    is_jupyter_run: false
    is_kaggle_kernel: true
    python_version: 3.7.4
    start_time: 1634397365
    t:
      1:
      - 1
      - 3
      - 5
      2:
      - 1
      - 3
      - 5
      3:
      - 16
      4: 3.7.4
      5: 0.12.4
      8:
      - 2
      - 5
arch:
  desc: null
  value:
    args:
      fc_hidden: 512
      n_feats: 128
    type: BatchOverfitModel
augmentations:
  desc: null
  value:
    spectrogram: []
    wave: []
data:
  desc: null
  value:
    train:
      batch_size: 20
      datasets:
      - args:
          limit: 20
          max_audio_length: 20.0
          max_text_length: 200
          part: train-clean-100
        type: LibrispeechDataset
      num_workers: 5
    val:
      batch_size: 20
      datasets:
      - args:
          limit: 20
          max_audio_length: 20.0
          max_text_length: 200
          part: dev-clean
        type: LibrispeechDataset
      num_workers: 5
loss:
  desc: null
  value:
    args: {}
    type: CTCLoss
lr_scheduler:
  desc: null
  value:
    args:
      anneal_strategy: cos
      epochs: 50
      max_lr: 0.004
      pct_start: 0.2
      steps_per_epoch: 100
    type: OneCycleLR
metrics:
  desc: null
  value:
  - args:
      name: WER (argmax)
    type: ArgmaxWERMetric
  - args:
      name: CER (argmax)
    type: ArgmaxCERMetric
n_gpu:
  desc: null
  value: 1
name:
  desc: null
  value: default_config
optimizer:
  desc: null
  value:
    args:
      lr: 0.0003
    type: SGD
preprocessing:
  desc: null
  value:
    spectrogram:
      args: {}
      type: MelSpectrogram
    sr: 16000
trainer:
  desc: null
  value:
    early_stop: 100
    epochs: 50
    grad_norm_clip: 10
    len_epoch: 10
    monitor: min val_loss
    save_dir: saved/
    save_period: 5
    verbosity: 2
    visualize: wandb
    wandb_project: asr_project
